<?xml version="1.0" encoding="utf-8"?>
<scanner xmlns:add="http://czt.sourceforge.net/templates/additional">
/*
  Copyright (C) 2004, 2005, 2006, 2007 Petra Malik
  This file is part of the CZT project: http://czt.sourceforge.net

  The CZT project contains free software; you can redistribute it and/or
  modify it under the terms of the GNU General Public License as published
  by the Free Software Foundation; either version 2 of the License, or
  (at your option) any later version.

  The CZT project is distributed in the hope that it will be useful,
  but WITHOUT ANY WARRANTY; without even the implied warranty of
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  GNU General Public License for more details.

  You should have received a copy of the GNU General Public License along
  with CZT; if not, write to the Free Software Foundation, Inc.,
  59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
*/

package <package/>;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.logging.Level;

import net.sourceforge.czt.parser.util.ScanException;
import net.sourceforge.czt.parser.util.CyclicParseManager;
import net.sourceforge.czt.parser.util.ErrorType;
import net.sourceforge.czt.parser.util.LatexMarkupFunction;
import net.sourceforge.czt.parser.util.LatexMarkupFunctionVisitor;
import net.sourceforge.czt.parser.util.LatexSym;
import net.sourceforge.czt.parser.util.Lexer;
import net.sourceforge.czt.parser.util.LocInfo;
import net.sourceforge.czt.parser.util.LocInfoImpl;
import net.sourceforge.czt.parser.util.LocToken;
import net.sourceforge.czt.parser.util.MarkupDirective;
import net.sourceforge.czt.parser.util.MarkupException;
import net.sourceforge.czt.parser.util.Pair;

import net.sourceforge.czt.parser.z.CyclicParentError;
import net.sourceforge.czt.parser.z.ZParseError;
import net.sourceforge.czt.parser.z.ZParseMessage;
import net.sourceforge.czt.session.CommandException;
import net.sourceforge.czt.session.Key;
import net.sourceforge.czt.session.SectionInfo;
import net.sourceforge.czt.session.Source;
import net.sourceforge.czt.util.CztException;
import net.sourceforge.czt.z.ast.ZSect;
import net.sourceforge.czt.util.CztLogger;
import net.sourceforge.czt.z.ast.Directive;
import net.sourceforge.czt.z.ast.DirectiveType;
import net.sourceforge.czt.z.util.Factory;
import net.sourceforge.czt.util.Section;
import net.sourceforge.czt.z.util.ZChar;
import net.sourceforge.czt.z.util.ZString;


/**
 * A latex markup parser that looks like a scanner.
 * Instances of this class are usually used after the Latex2Unicode
 * converter.  It preprocesses the output of the converter and updates
 * the markup function appropriately.  It is possible to use the same
 * markup function in the converter if each markup command is used
 * AFTER it is defined in a markup directive.
 */
public class <class/>
  implements Lexer
{
  private static Factory factory_ = new Factory();

  /**
   * The latex to unicode scanner that provides the input.
   */
  private LatexLexer lexer_;

  /**
   * Section information.
   */
  private SectionInfo sectInfo_;

  /**
   * The markup function for the current section.
   */
  private LatexMarkupFunction markupFunction_ = null;

  /**
   * All markup functions created so far.
   */
  private Map&lt;String,LatexMarkupFunction&gt; markupFunctions_ =
    new HashMap&lt;String,LatexMarkupFunction&gt;();

  /**
   * Are we just parsing a section header?
   */
  private boolean sectHead_ = false;

  /**
   * The current section name.
   */
  private String sectName_ = null;

  /**
   * The parents of the current section.
   */
  private String parents_ = null;

  /**
   * The token returned by the last call to method next_token.
   */
  private LocToken symbol_ = null;

  /**
   * Creates a new latex markup parser that uses the scanner provided.
   * The section information should be able to provide information of type
   * &lt;code&gt; 
   * net.sourceforge.czt.parser.util. LatexMarkupFunction.class&lt;/code&gt;.
   * @param lexer
   * @param sectInfo
   */
  public <class/>(LatexLexer lexer, SectionInfo sectInfo)
  {
    lexer_ = lexer;
    sectInfo_ = sectInfo;
  }

  @Override
  public Source getSource()
  {
    return lexer_.getSource();
  }

  /**
   * Adds the markup function of the given specification
   * to the current markup function.
   *
   * @param parent the name of the parent specification.
   */
  private void addMarkupFunction(String parent)
  {
    if (markupFunction_ == null) {
      markupFunction_ = new LatexMarkupFunction(sectName_);
      markupFunctions_.put(sectName_, markupFunction_);
      lexer_.setMarkupFunction(markupFunction_);
    }
    LatexMarkupFunction markupFunction = markupFunctions_.get(parent);
    if (markupFunction == null) {
      try {
        Key&lt;LatexMarkupFunction&gt; key = new Key&lt;LatexMarkupFunction&gt;(parent, LatexMarkupFunction.class);
        markupFunction = sectInfo_.get(key);
      }
      catch (CommandException exception) {
        String message = "Cannot get LatexMarkupFunction for " + parent
          + "; try to continue anyway";
        CztLogger.getLogger(LatexMarkupFunctionVisitor.class).warning(message);
      }
    }
    if (markupFunction != null) {
      try {
        markupFunction_.add(markupFunction);
      }
      catch (MarkupException e) {
        reportError(e);
      }
    }
  }

  private boolean is(LocToken token, LatexSym sym)
  {
    return token.getName().equals(sym.toString());
  }

  /**
   * This method checks the section manager state for various cases to be handled by this low level scanner/parser.
   * This is the most complicated case to cater for because LMF is scanning (e.g., prior to parsin), yet it happens
   * during the parsing of parents, which might lead to overlapping transactions and special care is needed in this
   * bootstrapping scenario. Given test cases, we managed to find a good compromise to the protocol that gets a bit
   * complicated, albeit deterministic.
   *
   * @param sectName same as sectName_, but to emphasise the dependency
   */
  private void ensureSectInfoStateForSpec(String sectName)
  {
    // set sectName_ first
    assert sectName.equals(sectName_);

    Key&lt;LatexMarkupFunction&gt; lmfKey = new Key&lt;LatexMarkupFunction&gt;(sectName, LatexMarkupFunction.class);

    // NOTE: don't start the transaction as it might not have been cancelled - see ensures below
    //
    // start the transaction from the Spec, as the ZSect chains won't
    // sectInfo_.startTransaction(lmfKey);

    // NOTE: when file "./foo.XXX" (Unicode or LaTeX) doesn't have a section foo but say "test"
    //       the Spec case gets a bit confused (e.g., SectManager already has "test" keys....
    //       So no need for transactions on already cached keys
    //
    // Use ensure for Spec (anonynimous or otherwise). Ensures there is a transaction for LMF - it might be
    // cancelled by LMF Command for LaTeX source; it might not when either the user gives the ZSect or the ZSect is Unicode
    // sectInfo_.ensureTransaction(lmfKey);

    // Only if the key isn't already calculated, and there isn't already a transaction for the LMF key, add one.
    // The usual case is that of "startTransaction(lmfKey)". Cases where it differ are:
    //
    // a) LaTeX printing of Unicode parsed source - there won't be a LMF cached, but there is already a ZSect.
    //    In that case, the transaction will be started - get(lmfKey) - but not cancelled - LmfCmd.
    //
    // b) LaTeX parsing of LaTeX source where SECTION name isn't linked to the Source file/str etc.
    //    In that case, there is already a ZSect (and LMF) cached, hence no need for transaction at all.
    //    If one had made the SECTION name the same as the file, this wouldn't be necessary.
    //
    //if (!sectInfo_.isCached(lmfKey))
    //{
    //  sectInfo_.ensureTransaction(lmfKey);
    //}

    // NOTE: at typechecker, we got the RedecleredSection example, which triggers a lexing case here.
    //       we needed to remove the key first; otherwise we would lex two equal header twice, hence
    //       keep the section manager in an inconsistent state before getting to the type error case.
    //       so when lexing lexing the second copy, we need to remove the first one.
    //
    if (sectInfo_.isCached(lmfKey))
    {
      // this remove works because there is no link with LMF and Spec
      //sectInfo_.removeKey(lmfKey);
      
      ZParseError error = new ZParseError(ZParseMessage.MSG_ERROR_REDECLARED_ZSECT,  new Object[] { sectName }, null);
      error.setErrorType(ErrorType.ERROR);
      error.setInfo("There might be duplicate section or files?");
      ZParseError.report(sectInfo_, getSource(), error);

      // use the ZParseError as a LocInfo - TODO: maybe put it as last seen Token later?
      throw new ScanException(error.getMessage(), error);
    }
    sectInfo_.startTransaction(lmfKey);
  }

  @Override
  public LocToken next()
    throws IOException
  {
    final LocToken token = lexer_.next();
    if (token == null) {
      updateLatexMarkupFunction();
      return token;
    }
    final boolean isStartOfAnonymousSpec =
      ! sectHead_ &amp;&amp; sectName_ == null &amp;&amp;
        (is(token, LatexSym.CHAR_MARKUP) ||
         is(token, LatexSym.WORD_MARKUP) ||
         is(token, LatexSym.INWORD_MARKUP) ||
         is(token, LatexSym.PREWORD_MARKUP) ||
         is(token, LatexSym.POSTWORD_MARKUP) ||
         is(token, LatexSym.UNICODE));
    if (isStartOfAnonymousSpec) {
      // we are parsing an anonymous specification
      sectName_ = Section.ANONYMOUS.getName();

      // depends on sectName_ : update it first
      ensureSectInfoStateForSpec(sectName_);

      parents_ = Section.STANDARD_TOOLKIT.getName()
        <add:oz>+", oz_toolkit"</add:oz>
        <add:circus>+", circus_prelude"</add:circus>
        <add:zeves>+", zeves_prelude"</add:zeves>;
      addMarkupFunction(Section.PRELUDE.getName());
<add:oz>
      addMarkupFunction("oz_toolkit");
</add:oz>
<add:circus>
      addMarkupFunction("circus_prelude");
</add:circus>
<add:zeves>
      addMarkupFunction("zeves_prelude");
</add:zeves>
      addMarkupFunction(Section.STANDARD_TOOLKIT.getName());
    }
    if (sectHead_) { // we are just parsing a section header
      if (is(token, LatexSym.END)) { // end of section header
        sectName_ = trim(sectName_);

        ensureSectInfoStateForSpec(sectName_);
        
        markupFunction_ = new LatexMarkupFunction(sectName_);
        markupFunctions_.put(sectName_, markupFunction_);
        lexer_.setMarkupFunction(markupFunction_);
        if (! sectName_.equals("prelude")) {
          addMarkupFunction("prelude");
        }
<add:oz>
        if (! sectName_.equals("prelude") &amp;&amp;
            ! sectName_.equals("oz_toolkit")) {
          addMarkupFunction("oz_toolkit");
        }
</add:oz>
<add:circus>
        /* Educated guess that it is needed based on Oz code */
        if (! sectName_.equals("prelude") &amp;&amp;
            ! sectName_.equals("circus_prelude")) {
          addMarkupFunction("circus_prelude");
        }
</add:circus>
<add:zeves>
        /* Educated guess that it is needed based on Oz code */
        if (! sectName_.equals("prelude") &amp;&amp;
            ! sectName_.equals("zeves_prelude")) {
          addMarkupFunction("zeves_prelude");
        }

        // extra elements for zeves_toolkit implicitly added
        if (sectName_.equals("zeves_toolkit"))
        {
          addZEvesImplicitMarkupDirectives(token);
        }
</add:zeves>
        if (parents_ != null) {
          String[] parents = parents_.split(",");
          List&lt;String&gt; parentList = new ArrayList&lt;String&gt;();
          for (String parent : parents) {
            parent = trim(parent);
            if (parent != null &amp;&amp; ! parent.equals("")) {
              parentList.add(parent);
            }
          }
          
          // use the cyclic manager to get valid parents avoiding cyclic recursion
          CyclicParseManager cyclicMan = CyclicParseManager.getManager(sectInfo_);
          List&lt;String&gt; validParents = cyclicMan.getValidParentNames(sectName_, parentList); 
          try {
            for (String parent : validParents) {
              addMarkupFunction(parent);
            }
          } finally {
            // mark section inactive and report cycles
            List&lt;List&lt;String&gt;&gt; cycles = cyclicMan.visitedParents(sectName_);
            for (List&lt;String&gt; cycle : cycles) {
              // report found cycles, if any, as warnings
              reportParentCycle(cycle, parentList);
            }
          }
          
        }
        sectHead_ = false;
      }
      else if (is(token, LatexSym.SECTION)) { // section token
        // start parsing section name
        sectName_ = "";
      }
      else if (is(token, LatexSym.PARENTS)) { // parents token
        // start parsing parents
        parents_ = "";
      }
      else {
        if (parents_ != null) {
          parents_ += token.spelling();
        }
        else if (sectName_ != null) {
          sectName_ += token.spelling();
        }
      }
    }
    else if (is(token, LatexSym.SECT)) { // begin of a section header
      updateLatexMarkupFunction();
      sectHead_ = true;
      parents_ = null;
      sectName_ = null;
    }
    else if (is(token, LatexSym.CHAR_MARKUP)) {
      Directive directive = parseCharMarkupDirective(token.spelling(),
                                                     token.getLocation());
      if (directive != null) {
        try {
          markupFunction_.add(directive);
        }
        catch (MarkupException e) {
          reportError(e);
        }
      }
      return next();
    }
    else if (is(token, LatexSym.WORD_MARKUP)) {
      parseWordMarkup(DirectiveType.NONE, token.getLocation());
    }
    else if (is(token, LatexSym.INWORD_MARKUP)) {
      parseWordMarkup(DirectiveType.IN, token.getLocation());
    }
    else if (is(token, LatexSym.PREWORD_MARKUP)) {
      parseWordMarkup(DirectiveType.PRE, token.getLocation());
    }
    else if (is(token, LatexSym.POSTWORD_MARKUP)) {
      parseWordMarkup(DirectiveType.POST, token.getLocation());
    }
    check(symbol_, token);
    if (token.spelling() != null) {
      symbol_ = token;
    }
    return token;
  }
  
  private void reportParentCycle(List&lt;String&gt; cycle, List&lt;String&gt; parents)
  {
    Pair&lt;String, String&gt; render = CyclicParseManager.renderParseParentCycle(cycle);
    String cycleParent = render.getFirst();
    String cycleStr = render.getSecond();
    
    int parentIndex = 0;
    for (String parent : parents) {
      if (cycleParent.equals(parent)) {
        // found the parent - report cycle with its location as a warning
        // note using dynamic location resolving errors here
        CyclicParentError.reportCyclicParentNoLoc(sectInfo_, getSource(), 
            sectName_, cycleParent, parentIndex, cycleStr);
        parentIndex++;
        // do not break, because several parents with the same name could be
        // listed - we need to report the same cycle for all of them
      }
    }
    
    if (parentIndex == 0) {
      // no applicable parent found? 
      // still report - using dummy location
      CyclicParentError.reportCyclicParent(sectInfo_, getSource(), cycleStr, 
          new LocInfoImpl(getSource().getName(), 0, 0));
    }
  }

  /**
   * Removes spaces and newlines before and after.
   */
  private String trim(String string)
  {
    String result = string.trim();
    while (result.startsWith(ZString.NLCHAR)) {
      result = result.substring(1).trim();
    }
    while(result.endsWith(ZString.NLCHAR)) {
      result = result.substring(0, result.length() - 1).trim();
    }
    return result;
  }

  @SuppressWarnings("unchecked")
  private void updateLatexMarkupFunction()
  {
    if (markupFunction_ != null) {
      final Key&lt;LatexMarkupFunction&gt; key =
        new Key&lt;LatexMarkupFunction&gt;(markupFunction_.getSection(), LatexMarkupFunction.class);


      // redeclared sections are considered type errors (!) but they happen at lexing time!!!!
      // we can't add duplicate keys, neither add one key for where there are not transactions!
      if (sectInfo_.isCached(key))
      {
        CztLogger.getLogger(LatexMarkupFunction.class).log(Level.WARNING, "About to add duplicate key ''{0}'' while updating LatexMarkupFunction. This might happen when keywords are missued in the specification", key.toString());
      }
      sectInfo_.endTransaction(key, markupFunction_,
         Collections.singleton(new Key&lt;ZSect&gt;(markupFunction_.getSection(), ZSect.class)));//dependencies());
      
      // get method on the just added LatexMarkupFunction to force the dependency for the calling ZSect being parsed
      // to contain the LMF itself . TODO: this is a hack given the intertwined relationship between LMF and ZS parsing.

      // NOTE: we added to the ZSect a dependency to a LMF in Parser.xml updateZSect. That is added even if the buffer is Unicode (!!!)
      //       in this way our sin is to have too many (or one spurious) dependency; hence we no longer need the hack below. 
      //       ex: this would result in a unicode ZSect depending on its (empty) LatexMarkupFunction key.
      //
      //       having this "hard-wired" dependency is also helpful because we don't if when we started the transaction for
      //       the ZSect LMF lexing took place or not. That's because it depends on the size of the CztReader buffer. So,
      //       this bootstrapping between low-level lexing and parsing becomes quite tricky. This was our compromise that is
      //       conservative enough to keep dependencies right for a consistent section manager state.
      //
      // HACK: whoever is using LatexMarkupParser and it is in a transaction will depend on it, even though might not be using it
      //       however, this isn't in itself a problem, given that LatexMarkupParsers are only used by Latex markup itself, which
      //       even if an empty latex markup is in place, it's okay to have an extra dependency. Trouble would be to have missed it.
      //       given the intertwined nature of parsing / lexing and LMF, we antecipate there isn't much we can do here. TODO:CHECK
      //try
      //{
      //  LatexMarkupFunction res = sectInfo_.get(key);
      //  assert res == markupFunction_;
      //}
      //catch (CommandException ex)
      //{
      //  final String message = "Couldn't retrieve LatexMarkupFunction " + markupFunction_.getSection() + " that has just been calculated?!";
      //  //Logger.getLogger(LatexMarkupParser.class.getName()).log(Level.WARNING, message, ex);
      //  throw new CztException(message, ex);
      //}
    }
  }

  private void check(LocToken t1, LocToken t2)
  {
    if (t1 != null &amp;&amp; t2 != null) {
      if (is(t1, LatexSym.UNICODE) &amp;&amp; is(t2, LatexSym.UNICODE)) {
        String s1 = t1.spelling();
        String s2 = t2.spelling();
        if (s1 != null &amp;&amp; s1.length() > 0 &amp;&amp;
            s2 != null &amp;&amp; s2.length() > 0) {
          final ZChar[] zchars1 = ZChar.toZChars(s1);
          final ZChar[] zchars2 = ZChar.toZChars(s2);
          ZChar c1 = zchars1[zchars1.length - 1];
          ZChar c2 = zchars2[0];
          final boolean c1IsLetterOrDigit =
            ZChar.isDigit(c1) || ZChar.isLetter(c1);
          final boolean c2IsLetterOrDigit =
            ZChar.isDigit(c2) || ZChar.isLetter(c2);
          final boolean c1IsDeltaOrXi =
            ZChar.DELTA.equals(c1) || ZChar.XI.equals(c1);
          final boolean cond =
            c1IsLetterOrDigit &amp;&amp; c2IsLetterOrDigit &amp;&amp; 
              ! c1IsDeltaOrXi;
          if (cond) {
            ZParseError.report(sectInfo_,
                               getSource(),
                               ErrorType.WARNING,
                               ZParseMessage.MSG_POSSIBLE_MISSING_SPACE,
                               new Object[0],
                               t2.getLocation());
          }
        }
      }
    }
  }

  private void parseWordMarkup(DirectiveType type, LocInfo location)
    throws IOException
  {
    String name = parseName();
    String latex = parseUnicode();
    Directive directive = factory_.createDirective(name, latex, type);
    directive.getAnns().add(factory_.createLocAnn(location.getSource(),
                                                  location.getLine(),
                                                  null));
    try {
      markupFunction_.add(directive);
    }
    catch (MarkupException e) {
      reportError(e);
    }
  }

  private String parseName()
    throws IOException
  {
    LocToken token = lexer_.next();
    if (is(token, LatexSym.NAME)) {
      return token.spelling();
    }
    System.err.println("Error while parsing markup directive.");
    return null;
  }

  private String parseUnicode()
    throws IOException
  {
    String result = "";
    LocToken token = lexer_.next();
    while (token != null &amp;&amp;
           ! is(token, LatexSym.END_MARKUP)) {
      result += token.spelling();
      token = lexer_.next();
    }
    return result;
  }

  public static Directive parseCharMarkupDirective(String directive,
                                                   LocInfo loc)
  {
    String[] splitted = directive.split("[ \t]+");
    final int expectedLength = 3;
    if (splitted.length == expectedLength) {
      DirectiveType type = DirectiveType.NONE;
      String name = splitted[1];
      if ("%%Zprechar".equals(splitted[0])) {
        type = DirectiveType.PRE;
      }
      else if ("%%Zpostchar".equals(splitted[0])) {
        type = DirectiveType.POST;
      }
      else if ("%%Zinchar".equals(splitted[0])) {
        type = DirectiveType.IN;
      }

      if (splitted[2].startsWith("U+")) {
        final int beginString = 2;
        final int endString = 6;
        String hexValue = splitted[2].substring(beginString, endString);
        final int hexBase = 16;
        int decimal = Integer.parseInt(hexValue, hexBase);
        char[] chars = Character.toChars(decimal);
        String unicode = new String(chars);
        Directive d = factory_.createDirective(name, unicode, type);
        d.getAnns().add(factory_.createLocAnn(loc.getSource(),
                                              loc.getLine(),
                                              null));
        return d;
      }
      else if (splitted[2].startsWith("U-")) {
        final int beginString = 2;
        final int endString = 10;
        String hexValue = splitted[2].substring(beginString, endString);
        final int hexBase = 16;
        int decimal = Integer.parseInt(hexValue, hexBase);
        char[] chars = Character.toChars(decimal);
        String unicode = new String(chars);
        Directive d = factory_.createDirective(name, unicode, type);
        d.getAnns().add(factory_.createLocAnn(loc.getSource(),
                                              loc.getLine(),
                                              null));
        return d;
      }
      System.err.println("WARNING: Cannot parse " + directive);
      return null;
    }
    System.err.println("WARNING: Cannot parse " + directive);
    return null;
  }

  private void reportError(MarkupException e)
  {
    MarkupDirective d1 = e.getMarkupDirective1();
    MarkupDirective d2 = e.getMarkupDirective2();
    Object[] args = { d1.getCommand(), d1, d2 };
    LocInfo location = new LocInfoImpl(getSource().toString(),
                                       d2.getLine().intValue(),
                                       -1,
                                       -1,
                                       -1);
    ZParseError.report(sectInfo_,
                       getSource(),
                       ErrorType.ERROR,
                       ZParseMessage.MSG_LATEX_COMMAND_DEFINED_TWICE,
                       args,
                       location);
    args = null;
  }

  <add:zeves>
  private void addZEvesImplicitMarkupDirectives(LocToken token)
  {
    // adds manually applies$to directive as Zinword applies\$to applies$to
    Directive directive = factory_.createDirective("applies\\$to", "applies$to", DirectiveType.IN);
    directive.getAnns().add(factory_.createLocAnn(token.getLocation().getSource(),
                                                  token.getLocation().getLine(),
                                                  null));
    try {
      markupFunction_.add(directive);
    }
    catch (MarkupException e) {
      reportError(e);
    }
  }
  </add:zeves>

  public interface LatexLexer
    extends Lexer
  {
    void setMarkupFunction(LatexMarkupFunction markupFunction);
  }
}
</scanner>
