\documentclass{llncs}
\pagestyle{headings}   % turn on page numbers
\usepackage{epsf}

\usepackage{url}

\newcommand{\Circus}{{\sf\slshape Circus}}
\newcommand{\Class}[1]{\texttt{#1}}
\newcommand{\Element}[1]{\texttt{#1}}
\newcommand{\Interface}[1]{\texttt{#1}}
\newcommand{\Method}[1]{\texttt{#1}}

\begin{document}
\title{CZT support for Z extensions}
\author{Leo Freitas \and Tim Miller \and Petra Malik \and Mark Utting}
\maketitle

\begin{abstract}
  An integrated framework for supporting multiple dialects of a formal
  notation.
\end{abstract}

\section{Introduction} \label{sec:intro}

  The Z language~\cite{isoz} is a formal specification language that
  can be used to precisely specify the behaviour of systems, and
  analyse it via proof, animation, test generation etc.  The Community
  Z Tools (CZT) project~\cite{czt} is an open-source Java framework
  for building formal methods tools for Z and Z dialects.

  In recent years, there has been an increasing interest in combining
  different programming paradigms within an uniform formal notation,
  where Z plays a central role. This gave rise to many Z dialects that
  includes process
  algebras~\cite{fischer-1998,fischer-2000,circus.sem:intro}, object
  orientation~\cite{oz,ohcircus},
  time~\cite{tcoz,circus.sem:real.time2},
  mobility~\cite{circus.sem:mobility}, and so forth.

  Among these extensions, CZT supports Object-Z~\cite{oz} with
  parsing, typechecking, and other facilities.  [TODO: Write something
  short about Object-Z].  Currently, we are working on extensions for
  Timed Communicating Object-Z (TCOZ)~\cite{tcoz} and
  \Circus~\cite{circus.sem:intro}.  [TODO: Write something about
  TCOZ].  \Circus\ is an unified refinement language that combines Z,
  CSP~\cite{csp.books:roscoe}, and the refinement
  calculus~\cite{fm.ref:morgan}, with Hoare and He's \textit{Unifying
  Theories of Programming} (UTP) as the semantic
  background~\cite{hoare.utp}.

  [TODO: write more]

\section{XML Schemas}

  The first step in designing the CZT tools and libraries was the
  development of an XML Schema that describes an XML markup for Z
  specifications (ZML)~\cite{UttEA:03}.  This is an interchange format
  that can be used to exchange parsed and even typechecked Z
  specifications between sessions and tools.

  Another attempt to represent Z with XML is been explored with the
  Z/Eves theorem prover~\cite{tp.tools:zeves.ref}. It allowed one to
  create a customised theorem prover with additional tactics tailored
  for a particular specification by modifying the XML representation
  of the Z specification in Z/Eves~\cite{tp.tools:zeves.api}.

  Standard Z allows specifications to be exchanged using Unicode,
  \LaTeX\ or email markup.  However, implementing a parser for such
  specifications is a non-trivial task that might take several weeks
  or even months to be finished.  ZML, in contrast, can be parsed
  immediately using one of the available XML parsers like
  Xerces\footnote{\url{http://xml.apache.org/xerces-j/}} or
  Crimson\footnote{\url{http://xml.apache.org/crimson/}}.

  Tools also benefit from being able to annotate terms with type
  information, anticipated usage, comments, and so on.  The ZML format
  allows such annotations. [TODO: are there other advantages of ZML?]

  The XML Schema for ZML has been carefully designed to be extensible
  in order to allow Z dialects and extensions to profit from those
  advantages as well.  The following strategies have been used to
  achieve this.

  The \textit{``any''} element can be used in an XML Schema to enable
  instance XML documents to contain additional elements not specified
  by the schema.  This concept has been used to define annotations.
  That is, an annotation to a term can either be one of the
  annotations defined in the XML Schema for Z or any other kind of
  data.  This allows a tool builder to decide what data makes sense
  for a particular tool.

  Secondly, inheritance is used extensively throughout the XML Schema.
  Abstract elements are used to provide placeholders for their derived
  elements.  For example, the abstract element \Element{Para} is the
  parent of all concrete Z paragraphs like, for example, axiomatic
  paragraphs (element \Element{AxPara}) and free types paragraph
  (element \Element{FreePara}).  This makes it easy to include a
  reference to any kind of paragraph into other elements as, for
  example, in the definition of a Z section (element \Element{ZSect})
  which contains a sequence of paragraphs.

  More important is, however, that the inheritance hierarchy defined
  in the XML Schema for ZML can be extended without even touching the
  ZML Schema file.  For example, the XML Schema for Object Z imports
  the ZML Schema file and defines a new paragraph for classes (element
  \Element ClassPara) that is derived from element \Element{Para}
  defined in the ZML Schema.  Instance documents of the Object Z
  Schema can now contain class paragraphs in addition to the Z
  paragraphs wherever a paragraph is expected.  The same strategy has
  been used to define expression (abstract element \Element{Expr}),
  predicates (abstract element \Element{Pred}), declaration (abstract
  element \Element{Decl}) and others, making it possible for
  extensions to add new kinds of expressions, predicates, etc.

  This can be carried on to extending an extension.  For example, the
  additional elements provided by the Object Z Schema are further
  extended by the TCOZ Schema.  Again, the definitions of the elements
  for TCOZ are encapsulated into a TCOZ Schema file, and the ZML or
  Object Z Schema do not need to be modified.

  [TODO: are there other things that make the Schema extensible?]

  The use of XML in the CZT has shown as an efficient and extensible
  solution for representing a Z specification and its dialects.  The
  XML approach helps to clarify design decisions in a straightforward
  fashion.  This representation is the key for the integrated
  development and exchange of information between different Z tools.

 \section{Java AST Classes}

  The Java \emph{annotated syntax tree} (AST) provides a tree view of
  a parsed specification using Java interfaces and classes.  This
  allows easy access to syntactical objects like, for instance,
  paragraphs, predicates, and expressions, from within Java programs.

  The CZT Java AST interfaces and classes were automatically generated
  from the XML Schemas described in the previous section using our
  code generator \emph{GnAST} (GeNerator for AST).  The generated code
  looks similar to the code Java data binding tools like
  JAXB\footnote{\url{http://java.sun.com/xml/jaxb/}} or
  Castor\footnote{\url{http://www.castor.org/}} are producing.  The
  generated Java interfaces and classes represent the structures
  defined in the XML Schema instance document.  While the main purpose
  of a Java binding tool is to provide the ability to convert from XML
  format to Java objects and vice versa, the main purpose of GnAST is
  to generate well-designed AST classes.  For example, the AST classes
  generated by GnAST support the visitor design pattern described
  later on.

  GnAST has also been used to generate AST interfaces and classes for
  Object Z, TCOZ, and \Circus.  This provides a very convenient way to
  obtain AST's for Z extensions that fit well into the AST for
  Standard Z.  That is, the AST classes for Z extensions also support
  the visitor design pattern described below.

  The visitor design pattern~\cite{GamEA:95,MaiCha:01} makes it very
  easy to write tools like typechecker, printer, etc.\ that need to
  traverse an AST. It provides a way to separate the structure of a
  set of objects from the operations performed on these objects.  This
  allows a new operation to be defined without modifying the AST
  classes.  To define a new operation, all you need to do is to
  implement a new visitor class.

  In CZT, a visitor interface is defined for every AST class,
  including abstract superclasses.  So, if a visitor implements this
  interface, say \Interface{AxPara}, then any \Interface{AxPara} AST
  nodes that it visits will call the visitor's \Method{visitAxPara}
  method.  However, if the visitor does not implement the
  \Interface{AxParaVisitor} interface, then the \Interface{AxPara} AST
  nodes will search up though their superclasses and call the first
  \Method{visit$AAA$} method that the visitor implements (for example,
  \Interface{visitPara} or \Interface{visitTermA} or
  \Interface{visitTerm}, the superclasses of \Interface{AxPara}).
  With this approach, the AST classes themselves take care of calling
  the closest (with respect to the inheritance hierarchy)
  \Method{visit} method implemented by the visitor.

  This flexibility and independency of visitors is very useful during
  the development of new tools.  As the hierarchy trees of different
  language entities are independent, one can implement visiting
  methods for specific parts of the language such as declarations or
  paragraphs.  That allows one to implement the hierarchy trees
  piecemeal, checking the conformance within every stable subset.
  Whenever problems are found, they are contained within the visit
  methods for the particular hierarchy tree, hence improving debugging
  and maintainability.  For instance, in the development of the
  \Circus\ compiler used in a model checking
  tool~\cite{circus.mc:leo}, the use of CZT visitors allowed the
  implementation of the smallest subset needed for initial testing.
  This makes the CZT visitor not only an elegant object oriented
  solution, but also the ground for consistent rapid prototyping.

\section{Parsers, Typecheckers and other Tools}

  CZT includes a suite of important tools for things such as parsing,
  typechecking, and markup conversion. In addition to a parser and
  typechecker for Z, an Object Z parser is provided, and a \Circus\
  parser, Object-Z typechecker, and TCOZ parser are under development.
  The Object Z, TCOZ, and \Circus\ tools extend the Z tools by adding
  support for the additional constructs that languages provide.  Each
  dialect is an extension of Z, so it is tempting to just keep adding
  to the tools for each extension and use the largest superset of all
  dialects. For example, use the TCOZ tools to parse and typecheck
  Z. However, this has two distinct problems. Firstly, one aim of the
  CZT project is to create tools that strongly conform to the Z
  standard, so allowing extra constructs and different type rules will
  break the strong conformance. Secondly, the extensions of Z are not
  linear. For example, Object-Z extends Z with class paragraphs, and
  TCOZ extends Object-Z with concurrency operators, but \Circus\ extends
  neither of these - only Z. Therefore, CZT requires an approach that
  produces separate tools for each dialect, maximises the commonality
  between the parsers, and minimises versioning and maintenance
  problems via reuse.

% Petra: Why is this uncommented? It sounds quite nice!

%Unfortunately, it is quite difficult to reuse code from an
%automatically generated scanner or parser, and Java Cup does not
%provide means to do so.  To avoid duplicated code, XML templates are
%used that contain the different parser and scanner variants.  From
%this, the different source files are generated.  This maximises the
%commonality between the parsers and minimises versioning and
%maintenance problems.

  \begin{itemize}
    \item[LEO] Here Tim or I could include the basics for setting up
               and extending parsers. {\bf Tim:} Done!
    \item[LEO] Worthwhile mentioning performance penalties as the
               section manager, OpTable, and DefinitionTable, are
               quite slow. {\bf Petra:} Not sure that the section
               manager is slow; I guess it would be slower without a
               section manager.
  \end{itemize}


\subsection{Parsers and Scanners}

  CZT includes parsers for Standard Z specifications given either in
  Unicode or using \LaTeX\ mark-up.  Support for e-mail mark-up is
  planned. To produce different parsers and scanners for Z and its
  dialects, CZT uses XML templates, and generates the code from these
  templates using XSL. Java Cup\footnote{See
  \url{http://www.cs.princeton.edu/\~{}appel/modern/java/CUP/}} is
  used to generate the CZT parsers from an LALR grammar, and
  JFlex\footnote{See \url{http://jflex.de/}} is used to generate the
  scanners. Neither of these tools explicitly supports inheritance for
  parser or scanners respectively.

The parser and scanner for all dialects are maintained in two master
XML files: one for the parser and one for the scanner. Each master
file contains several XML tags that are used for substituting text for
the dialects. For example, the tag {\tt <package/>} is placed wherever
one would normally write the Java package name, so that each parser
and scanner can be contained in their own package. The tags {\tt
<add:}{\em dialect}{\tt >} and {\tt </add:}{\em dialect}{\tt >} are
used to wrap around code that are specific to particular dialects. So
to add a new type of expression to the Object-Z parser, one would add
a new production to the expression rule in the master file, and place
it between the {\tt <add:oz>} and {\tt </add:oz>} tags.

To generate the individual Java Cup files for each dialect, XSLT is
used to include the necessary code, and to substitute in values for
tags. For example, to generate the Object-Z parser, XSLT is applied to
the master file, and supplied with these three arguments in the Ant
script used to build the parser:
\begin{enumerate}
  \item {\tt param name="class" expression="Parser"}
  \item {\tt param name="package" expression="net.sourceforge.czt.parser.oz"}
  \item {\tt param name="add" expression="{oz}"}
\end{enumerate}

This specifies that each instance of the tag {\tt class} is
substituted with {\tt Parser}, each instance of {\tt package} with
{\tt net.sourceforge.czt.parser.oz}, and that anything between the
{\tt <add:oz>} and {\tt </add:oz>} tags is to be included. Additional
arguments including the input and output files are also required.

Similar rules are specified for each dialect. The result is a series
of Java Cup and JFlex files, one for each dialect, which can then be
used to generate the parser and scanner code.

\subsection{Multiple Markups}

 CZT supports multiple markups for each dialect.  The different
 mark-up languages suit different communities.  For example, \LaTeX\
 is prefered by researchers while Unicode WYSIWYG editing might be
 more attractive for students or industrial users. At present,
 Unicode, \LaTeX, and the ZML format \cite{UttEA:03} are supported,
 but adding additional markups is straightforward, as this section
 will present.  ZML scanning will not be discussed here, because it is
 quite different to the other markups. For ZML, JAXB code ({\bf find a
 reference}) is used to covert the ZML into an abstract syntax tree.

The CZT parsers are markup independent, but all of our scanners will
provide their respective parsers with Unicode when scanning Z variable
names etc. The reason for this is straightforward: Z specifications
are made up of sections, with each section having a name and a list of
parent sections. The definitions in a parent section are included in
the child section for a specification. For example, the Z toolkit is
specified as a series sections in \LaTeX. Now, consider the case in
which a person would like to use the Z toolkit, but would like to use
Unicode for their own specifications. This would require CZT to
provide a Z toolkit in Unicode, because the names used for
declarations in the Z toolkit would be in \LaTeX~instead of
Unicode. To work around this problem, all markups are converted to
Unicode, therefore allowing different sections of a specification to
be written in different markups.

Therefore, CZT provides a Unicode scanner, which performs lexical
analysis on a Unicode stream and breaks it into the necessary
tokens. CZT's \LaTeX~scanner, instead of implementing all of the
scanner rules, converts its \LaTeX~stream into a Unicode stream. In
addition to solving the problem discussed above, this greatly
simplifies the \LaTeX~scanner, because much of the conversion is
straightforward in comparision to scanning Z tokens. Location
information is recorded in the ASTs using annotations on each of the
nodes, and this points to the location in the original specification.

Of course, the \LaTeX~to Unicode scanner needs to know how to convert
\LaTeX~tokens into Unicode. This is done by specifying, in the file,
the Unicode representation for each \LaTeX~token used. For example, in
the Z toolkit, the following rule is written specifying the \LaTeX~
token for powerset, \verb+\power+:
\begin{verbatim}
  %%Zprechar \power U+2119
\end{verbatim}

The {\tt \%\%Zprechar} keyword specifies that \verb+\power+ is a
prefix character (that is, the is always a hard space after it), and
that its Unicode equivalent is U+2119. There are similar operators for
postfix, infix, and nofix characters, as well as words.

An additional component parses these definitions, and records this in
a symbol table. Each time a \LaTeX~token is read, a lookup is
performed on this table to find the Unicode mapping. If the lookup
fails because the token is not in the table, a warning is issued, and
the \LaTeX~token is used, minus the \verb+\+ token at the
front. Therefore, for each new \LaTeX~token introduced into a
specification, a unique Unicode mapping must be provided for the
\LaTeX~to Unicode scanner, or be content with using the \LaTeX token's
base name.

To parser a specification written using a new markup, for example, the
Email text-based markup, one only has to implement an Email to Unicode
scanner.

This approach has additional advantage: the scanners can function as a
converters between different markups without have to parse the
specifications. This simplifies many other tools in the suite as
well. For example, the CZT tool suite provides printing of abstract
syntax trees into the different markups. However, instead of
implementing a printer for each markup, only a Unicode printer is
implemented, and converters are used to print the other markups.

\subsection{Extending Tools using Visitors}
\label{extending-visitors}

\subsection{Typecheckers}

Typecheckers in CZT are written in a much different way to the parsers
and scanners. While each Z dialect has its own typechecker, and reuse
is of high importance, using XML templates is unnecessary, because
Java interfaces and inheritance can be used to extend typecheckers.

The Z typechecker is the base implementation. Most of the typechecker
is written using visitors, which can be extended as discussed in
Section~\ref{extending-visitors}. There are a few additional classes
that are used, such as the class that performs the unification of two
types for type inference and for checking type consistency.

The typechecker is designed for extendability. Application of the type
rules is implemented using visitor classes. While it is tempting to
write the typechecker as one large visitor, this creates maintenance
problems as this visitor would be quite large. Therefore, the
type-rule visitors are split over several classes: one for
typechecking expressions, another for typechecking predicates,
etc. These will be referred to as the {\em type-rule visitors}.

However, the type-rule visitors require access to shared resources,
such as typing environments and the class for unification, as well as
common methods used throughout the implementation. So, each type-rule
visitor inherits an abstract class called {\tt Checker}. This class
contains the common methods that are to be used, as well as an
instance of a class called {\tt TypeChecker}. {\tt TypeChecker}
contains references to all of the shared resources that are required,
and each type-rule visitor is constructed using the same instance of
{\tt TypeChecker} for each copy of the typechecker that is
running. {\tt TypeChecker} also contains references to the instance of
each type-rule visitor, so they are able to call visit methods on each
other. Of course, this could all be implemented without the {\tt
TypeChecker} class by just passing each resource to a subclass, but
the approach that has been implemented allows extensions to the
typechecker to reuse constructors and other intialisation code.

To extend a typechecker for another dialect, a new package is created.
In this package, a new {\tt Checker} class is implemented, which
inherits the base {\tt Checker} class. In this new class, any common
methods that are to be used by the extended typechecker are
implemented. Then, new type-rule visitors are created; one for
expressions, one for predicates, etc.  These type-rule visitors
implement the visit methods only for additional constructs in the
language, or for constructs in the base language that may have
additional constraints. Clearly, this does not handle constructs in
the base language, so for each type-rule visitor, an instance to the
corresponding visitor of the base language (for example, the
expression visitor) is created. Then, an additional visit method is
implemented - one that ``catches'' all AST nodes for the base
language, and the base type-rule visitor is used to typecheck these
nodes. Finally, a new {\tt TypeChecker} class is created, which
inherits the base version, and instead of creating type-rule visitors
from the base typechecker, it creates them using the new type-rule
visitors. Because visitor interfaces are used, the underlying
implementation of the extended typechecker need not inherit from the
base typechecker, but the way to access these type-rule visitors via
the {\tt TypeChecker} class remains the same. Therefore, the same
piece of code that gets an expression to accept the expression
type-rule visitor in the base typechecker will accept the extended
type-rule visitor in the extended typechecker.

This is an unusual design, but it provides good support for
extension. An alternative approach is to extend the base type-rule
visitors for each new type-rule visitor. However, this means that the
common code implemented in the {\tt Checker} class must all be
implemented in the base {\tt Checker} class, which requires a strong
coupling between all of the typecheckers.

To help clarify this design, we present the design of the Z
typechecker, and the Object-Z typechecker that extends
it. Figure~\ref{tc-design} ({\bf not sure about this figure}) presents
a UML-like outline of the class design. From this figure, one can see
that the class {\tt oz.Checker} inherits from {\tt z.Checker}, and
then the type-rule visitors inherit from their respective {\tt
Checker} class.

\def\epsfsize#1#2{0.70#1}
\begin{figure}[t]
\begin{center}
%\epsfbox{tc-design.eps}
\label{tc-design}
\end{center}
\end{figure}
\def\epsfsize#1#2{\epsfxsize}

{\tt oz.ExprVisitor} implements visit methods for all additional
Object-Z constructs, as well as for {\tt Expr}, the super-interface of
all expression constructs. This is implement as follows:

\begin{verbatim}
  public Object visitExpr(Expr expr)
  {
    return expr.accept(zExprChecker_);
  }
\end{verbatim}

Therefore, when {\tt oz.ExprChecker} does not implement a visit method
for a particular expression, it calls the instance of {\tt
  z.ExprChecker} to visit that expression.

Other components of the typecheckers are also extended using
inheritance. For example, the class for unification is extended by
overriding the {\tt unify} method in that class. {\tt unify} takes two
types and attempts to unify them, returning whether the unification
was successful. For Object-Z, an additional type is needed to handle
instances of classes. The overriding method first checks if the types
of class types, and attempts unification on them. If they are not, the
overridden method is called using the {\tt super} keyword.


\subsection{Section Manager}

  (is independent of Z/Object-Z/\Circus\ etc.
  Can easily be extended with new kinds of objects, commands)

    \begin{itemize}
        \item[LEO] The SectionManager commands archiecture is a clever solution I believe worthwhile explaining.
    \end{itemize}

\section{Type Checking}

      The (future!) modular design, using interfaces and visitors,
      allows the core Z typechecker to be extended separately
      to handle Object-Z and \Circus.  (TODO!)

    \begin{itemize}
        \item[LEO] I can include my experiences in extending the Z:TypeChecker for \Circus.
                    I should also discuss with Tim some of the ideas for decoupling the type checker.
    \end{itemize}

\section{Animating}

    Animation of \Circus\ using Z animator???
      (Operational semantics of \Circus\ are in Z itself, so this makes a meta-level animation possible...)
    This could set the scenario for the possibilities CZT gives towards integration.

    \begin{itemize}
        \item[LEO] I can write here about the \Circus\ refinement engine that uses ZLive, as well as the compiler.
    \end{itemize}


\section{Other Tools}

    \begin{itemize}
        \item[LEO]
        There is another tool under development that translates \Circus\ (Latex) specifications into Java code.
        It uses JCSP (a java csp-occam library) that allows execution of \Circus.
        In the Z part, due to the lack of tools, extreme simplifications (via data refinement in the original \Circus)
        are needed.
        This tool could also use ZLive to be able to animate/execute (run!) more expressive \Circus\ specifications quite
        automatically, or at least minimise the data refinement effort required for the translation
    \end{itemize}


\section{Conclusions and Future Work} \label{sec:conclusions}

\section*{Acknowledgements}

\bibliographystyle{splncs}
\bibliography{ifm}

\end{document}
